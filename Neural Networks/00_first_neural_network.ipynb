{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Primera red neuronal con Pytorch\n",
    "\n",
    "La idea es desarrollar una red neuronal que pueda clasificar números basado en el dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comencemos importando las librerias.\n",
    "\n",
    "import torch # librería de pytorch\n",
    "import torch.nn as nn # contiene módulos para neural networks.\n",
    "import torch.optim as optim # optimización para entrenar modelos.\n",
    "import torchvision # contiene datasets y utilidades para visión por computadora.\n",
    "import torchvision.transforms as transforms # permite aplicar transformaciones a los datos.\n",
    "import matplotlib.pyplot as plt # para crear imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # Aqui vamos a tomar las imágenes y lo pasaremos a tensores, una característica de .ToTensor es que ya nos normaliza por 255, es decir cada valor lo divide entre 255\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Luego que pasamos a tensores, que tenemos valores entre o y 1, cuando normalizamos decimos que el primer valor es el promedio, es decir 0.5 y con una desviación estandar de 0.5 es decir, es decir [-1,1]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform) \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) # DataLoader: Organiza los datos en lotes de 64 imágenes y los baraja para mejorar el entrenamiento\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module): # decimos que nuetsra clase NeuralNetwork hereda de nn.Module\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__() # inicializamos la clase padre\n",
    "        self.fc1 = nn.Linear(784, 128) # primera capa 748 de datos de entrada y salen 128 \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear (64, 10) # capa de salida 10 clases\n",
    "        self.relu = nn.ReLU() # función de activación\n",
    "        self.softmax = nn.LogSoftmax(dim=1) # Genera la probabilidad de cada clase\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28) # aplanar la imagen 28x28 a un vector de 784\n",
    "        x = self.relu (self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de pérdida y optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork() # inicilizamos el modelo \n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # función de pérdida usada en clasificación multicase\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Algoritmo de optimización que ajusta los pesos, lr es el learning-rate que controla los pasos en el descenso del gradiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for epoch 1, Loss: 0.39417982474763763\n",
      "for epoch 2, Loss: 0.19143896014975714\n",
      "for epoch 3, Loss: 0.13771817340318965\n",
      "for epoch 4, Loss: 0.11249124705354606\n",
      "for epoch 5, Loss: 0.09651337888365838\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad() # reiniciar gradientes\n",
    "        output = model(images)\n",
    "        loss = criterion(output,labels) # cálcular pérdida\n",
    "        loss.backward()\n",
    "        optimizer.step() # actualizar pesos \n",
    "        running_loss += loss.item()\n",
    "    print(f\"for epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")  \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralnetwork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
